{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cccfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa428c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.7300e+02 2.1600e+03 2.1600e+03 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
      " [6.1100e+02 1.4040e+03 2.8080e+03 ... 0.0000e+00 1.8200e+02 1.0000e+00]\n",
      " [7.0500e+02 3.2400e+02 3.2400e+02 ... 1.0000e+00 3.3400e+02 1.0000e+00]\n",
      " ...\n",
      " [2.8671e+04 1.0800e+03 1.0800e+03 ... 0.0000e+00 2.9000e+01 0.0000e+00]\n",
      " [3.1134e+04 2.1600e+03 2.1600e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [3.2832e+04 1.6200e+03 1.6200e+03 ... 0.0000e+00 9.0000e+01 0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "raw_csv_data = np.loadtxt('Business_case_dataset.csv', delimiter = ',')\n",
    "print(raw_csv_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41519865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.7300e+02 2.1600e+03 2.1600e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [6.1100e+02 1.4040e+03 2.8080e+03 ... 0.0000e+00 0.0000e+00 1.8200e+02]\n",
      " [7.0500e+02 3.2400e+02 3.2400e+02 ... 0.0000e+00 1.0000e+00 3.3400e+02]\n",
      " ...\n",
      " [2.8671e+04 1.0800e+03 1.0800e+03 ... 0.0000e+00 0.0000e+00 2.9000e+01]\n",
      " [3.1134e+04 2.1600e+03 2.1600e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [3.2832e+04 1.6200e+03 1.6200e+03 ... 0.0000e+00 0.0000e+00 9.0000e+01]]\n"
     ]
    }
   ],
   "source": [
    "unscaled_inputs_all = raw_csv_data[:,0:-1]# store dataset but exclude target column\n",
    "print(unscaled_inputs_all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79993336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "targets_all = raw_csv_data[:,-1] #store only target column\n",
    "print(targets_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e97c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2237\n"
     ]
    }
   ],
   "source": [
    "num_one_targets = int(np.sum(targets_all)) # we count how many targets are 1 (meaning that the customer did buy again)\n",
    "zero_targets_counter=0 #we set a counter for targets that are 0 (meaning that the customer did not buy again)\n",
    "print(num_one_targets)\n",
    "\n",
    "indices_to_remove = [] #we want to create a \"balanced\" dataset, so we will have to remove some input/target pairs, and we declare a variable that will do that\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0: #we count that number of targets that are 0\n",
    "        zero_targets_counter+= 1\n",
    "        if zero_targets_counter > num_one_targets: #once there are as many 0's as 1's, we mark entries where target is 0\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "#we create 2 new variables, one that will contain the inputs, and one that will contain the targets\n",
    "#we delete all indices that we marked \"to remove\" in the loop above\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8e727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.45560485  1.18956512  0.36398846 ... -0.8635056  -0.20536617\n",
      "  -0.77240946]\n",
      " [-1.48242424 -0.33022754  1.10843845 ... -0.8635056  -0.20536617\n",
      "   1.16499791]\n",
      " [-1.47280202 -2.50135991 -1.74528653 ... -0.8635056   2.23179102\n",
      "   2.78305242]\n",
      " ...\n",
      " [ 1.73938284  1.18956512  0.36398846 ... -0.20129479 -0.20536617\n",
      "  -0.62337812]\n",
      " [ 1.7477767   1.18956512  0.36398846 ... -0.20129479 -0.20536617\n",
      "   0.21758442]\n",
      " [ 1.73559537  1.18956512  0.36398846 ... -0.20129479 -0.20536617\n",
      "  -0.51692717]]\n"
     ]
    }
   ],
   "source": [
    "#standardize the inputs (can try to run the algo without this line)\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors) \n",
    "print(scaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd6a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 4471 4472 4473]\n",
      "[4280 2156 3735 ...   28 3776 1351]\n",
      "[[ 0.24292234 -0.76445401 -0.75268653 ...  0.24017908 -0.20536617\n",
      "   2.42111918]\n",
      " [-1.40954102 -0.76445401 -0.75268653 ... -0.8635056  -0.20536617\n",
      "  -0.36789583]\n",
      " [-0.74939506  1.18956512  0.36398846 ...  0.49402656 -0.20536617\n",
      "  -0.72982908]\n",
      " ...\n",
      " [-1.50750344 -1.8500202  -1.37306153 ... -0.8635056  -0.20536617\n",
      "  -0.77240946]\n",
      " [-0.75277307  0.10399894 -0.25638654 ...  0.49402656 -0.20536617\n",
      "  -0.77240946]\n",
      " [ 0.52954177  1.18956512  0.36398846 ... -0.8635056  -0.20536617\n",
      "  -0.77240946]]\n"
     ]
    }
   ],
   "source": [
    "#Shuffle the data\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0]) #arange the indices from 0 - scaled.input max row # with a step of 1\n",
    "print(shuffled_indices)\n",
    "np.random.shuffle(shuffled_indices) #shuffle the sequence of indices\n",
    "\n",
    "#aligns the inputs and targets with the shuffled_indices\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]\n",
    "print(shuffled_indices)\n",
    "print(shuffled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d64cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807.0 3579 0.504889633975971\n",
      "217.0 447 0.4854586129753915\n",
      "213.0 448 0.47544642857142855\n"
     ]
    }
   ],
   "source": [
    "#splitting the data\n",
    "#count the samples in each subset. We want 80-10-10 distribution of training, validation, and testing\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "train_samples_count = int(0.8*samples_count) #set train sample count to 80% of the original input sample\n",
    "validation_samples_count = int(0.1*samples_count)#set validation sample count to 10% of the original input sample\n",
    "test_samples_count = samples_count- train_samples_count-validation_samples_count #test dataset containing all remaining data\n",
    "\n",
    "#create variables that record the inputs and targets for training\n",
    "train_inputs = shuffled_inputs[:train_samples_count]#grab 80% of the shuffled inputs 1 - - - - - - - - 8 - 10\n",
    "train_targets = shuffled_targets[:train_samples_count]#grab 80% of the shuffled targets 1 - - - - - - - - 8 - 10\n",
    "\n",
    "#create variables that record the inputs and targets for validation\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "#create variables that record the inputs and targets for testing \n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets),train_samples_count,np.sum(train_targets)/train_samples_count)\n",
    "print(np.sum(validation_targets),validation_samples_count,np.sum(validation_targets)/validation_samples_count)\n",
    "print(np.sum(test_targets),test_samples_count,np.sum(test_targets)/test_samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a25832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving in .npz format\n",
    "np.savez('Audiobooks_data_train', inputs=train_inputs,targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs,targets=validation_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs,targets=validation_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f8ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
